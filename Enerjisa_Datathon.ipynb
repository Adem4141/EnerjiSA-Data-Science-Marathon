{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c92e7e",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312d29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f0b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = pd.read_csv('generation.csv', sep=';')\n",
    "temperature = pd.read_csv('temperature.csv',sep=';')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "## dropping empty rows from datasets\n",
    "empty_rows_gener = generation[generation.isnull().any(axis = 1)].index\n",
    "generation.drop(empty_rows_gener,inplace= True)\n",
    "L = temperature.index[temperature.isna().all(axis=1)].tolist()\n",
    "temperature.drop(L,inplace= True)\n",
    "## temperature k覺sm覺nda generation olmayan k覺s覺m tet\n",
    "main = pd.merge(temperature,generation,on='DateTime',how = 'left')\n",
    "main['DateTime']= pd.to_datetime(main['DateTime'])\n",
    "main['AirTemperature'] = main['AirTemperature'].str.replace(',', '.').astype(float)\n",
    "main['EffectiveCloudCover'] = main['EffectiveCloudCover'].str.replace(',', '.').astype(float)\n",
    "main['ComfortTemperature'] = main['ComfortTemperature'].str.replace(',', '.').astype(float)\n",
    "main['RelativeHumidity'] = main['RelativeHumidity'].str.replace(',', '.').astype(float)\n",
    "main['WindSpeed'] = main['WindSpeed'].str.replace(',', '.').astype(float)\n",
    "main['Generation'] = main['Generation'].str.replace(',', '.').astype(float)\n",
    "#main = main.drop(['WWCode'],axis = 1)\n",
    "indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
    "main['two_hour_airtem'] = main.AirTemperature.rolling(window=indexer, min_periods=1).mean()\n",
    "main['two_hour_comfort'] = main.ComfortTemperature.rolling(window=indexer, min_periods=1).mean()\n",
    "main['two_hour_cloud'] = main.EffectiveCloudCover.rolling(window=indexer, min_periods=1).mean()\n",
    "main['two_hour_hum'] = main.RelativeHumidity.rolling(window=indexer, min_periods=1).mean()\n",
    "main['two_hour_wind'] = main.WindSpeed.rolling(window=indexer, min_periods=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89dd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addind two hourly mean atrributes of humidity, cloudcover and windspeed\n",
    "## lag features\n",
    "main.two_hour_hum = main.two_hour_hum + 0.0001\n",
    "main.two_hour_cloud = main.two_hour_cloud + 0.0001\n",
    "main.two_hour_wind = main.two_hour_wind + 0.0001\n",
    "\n",
    "main['prop_hum'] = main.two_hour_hum / main.two_hour_hum.shift(1)\n",
    "main['prop_cloud'] = main.two_hour_cloud / main.two_hour_cloud.shift(1)\n",
    "main['prop_wind'] = main.two_hour_wind / main.two_hour_wind.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bdacdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addind three hourly mean atrributes of humidity, cloudcover and windspeed\n",
    "## lead features\n",
    "\n",
    "main['prop_hum2'] = main.two_hour_hum / main.two_hour_hum.shift(-3)\n",
    "main['prop_cloud2'] = main.two_hour_cloud / main.two_hour_cloud.shift(-3)\n",
    "main['prop_wind2'] = main.two_hour_wind / main.two_hour_wind.shift(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b741387",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addind two hourly mean atrributes of humidity, cloudcover and windspeed\n",
    "\n",
    "main['prop_hum3'] = main.two_hour_hum / main.two_hour_hum.shift(-2)\n",
    "main['prop_cloud3'] = main.two_hour_cloud / main.two_hour_cloud.shift(-2)\n",
    "main['prop_wind3'] = main.two_hour_wind / main.two_hour_wind.shift(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82a34894",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Addind two hourly mean atrributes of humidity, cloudcover and windspeed\n",
    "\n",
    "main['prop_hum4'] = main.two_hour_hum / main.two_hour_hum.shift(-1)\n",
    "main['prop_cloud4'] = main.two_hour_cloud / main.two_hour_cloud.shift(-1)\n",
    "main['prop_wind4'] = main.two_hour_wind / main.two_hour_wind.shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e52e6",
   "metadata": {},
   "source": [
    "# CALCULATION OF SUN POSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42760b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sunpos(when, location, refraction):\n",
    "# Extract the passed data\n",
    "    year, month, day, hour, minute, second, timezone = when\n",
    "    latitude, longitude = location\n",
    "# Math typing shortcuts\n",
    "    rad, deg = math.radians, math.degrees\n",
    "    sin, cos, tan = math.sin, math.cos, math.tan\n",
    "    asin, atan2 = math.asin, math.atan2\n",
    "# Convert latitude and longitude to radians\n",
    "    rlat = rad(latitude)\n",
    "    rlon = rad(longitude)\n",
    "# Decimal hour of the day at Greenwich\n",
    "    greenwichtime = hour - timezone + minute / 60 + second / 3600\n",
    "# Days from J2000, accurate from 1901 to 2099\n",
    "    daynum = (\n",
    "        367 * year\n",
    "        - 7 * (year + (month + 9) // 12) // 4\n",
    "        + 275 * month // 9\n",
    "        + day\n",
    "        - 730531.5\n",
    "        + greenwichtime / 24\n",
    "    )\n",
    "# Mean longitude of the sun\n",
    "    mean_long = daynum * 0.01720279239 + 4.894967873\n",
    "# Mean anomaly of the Sun\n",
    "    mean_anom = daynum * 0.01720197034 + 6.240040768\n",
    "# Ecliptic longitude of the sun\n",
    "    eclip_long = (\n",
    "        mean_long\n",
    "        + 0.03342305518 * sin(mean_anom)\n",
    "        + 0.0003490658504 * sin(2 * mean_anom)\n",
    "    )\n",
    "# Obliquity of the ecliptic\n",
    "    obliquity = 0.4090877234 - 0.000000006981317008 * daynum\n",
    "# Right ascension of the sun\n",
    "    rasc = atan2(cos(obliquity) * sin(eclip_long), cos(eclip_long))\n",
    "# Declination of the sun\n",
    "    decl = asin(sin(obliquity) * sin(eclip_long))\n",
    "# Local sidereal time\n",
    "    sidereal = 4.894961213 + 6.300388099 * daynum + rlon\n",
    "# Hour angle of the sun\n",
    "    hour_ang = sidereal - rasc\n",
    "# Local elevation of the sun\n",
    "    elevation = asin(sin(decl) * sin(rlat) + cos(decl) * cos(rlat) * cos(hour_ang))\n",
    "    azimuth = atan2(\n",
    "        -cos(decl) * cos(rlat) * sin(hour_ang),\n",
    "        sin(decl) - sin(rlat) * sin(elevation),\n",
    "    )\n",
    "    azimuth = into_range(deg(azimuth), 0, 360)\n",
    "    elevation = into_range(deg(elevation), -180, 180)\n",
    "    if refraction:\n",
    "        targ = rad((elevation + (10.3 / (elevation + 5.11))))\n",
    "        elevation += (1.02 / tan(targ)) / 60\n",
    "    return (round(azimuth, 2), round(elevation, 2))\n",
    "def into_range(x, range_min, range_max):\n",
    "    shiftedx = x - range_min\n",
    "    delta = range_max - range_min\n",
    "    return (((shiftedx % delta) + delta) % delta) + range_min\n",
    "if __name__ == \"__main__\":\n",
    "    location = (40.602778, -104.741667)\n",
    "    when = (2022, 7, 4, 11, 20, 0, -6)\n",
    "    azimuth, elevation = sunpos(when, location, True)\n",
    "def get_angles(dt, refraction):\n",
    "    year, month, day = dt.year, dt.month, dt.day\n",
    "    hour, minute, second = dt.hour, dt.minute, dt.second\n",
    "    timezone = 3\n",
    "    when = (year, month, day, hour, minute, second, timezone)\n",
    "    location = (39.925533, 32.866287)\n",
    "    \n",
    "    angles = sunpos(when, location, refraction)\n",
    "    return angles\n",
    "def get_azimuth(dt, refraction=False):\n",
    "    angles = get_angles(dt, refraction)\n",
    "    return angles[0]\n",
    "def get_elevation(dt, refraction=False):\n",
    "    angles = get_angles(dt, refraction)\n",
    "    return angles[1]\n",
    "def abs_sin(value):\n",
    "    return abs(np.sin(value))\n",
    "main['Azimuth'] = main.DateTime.apply(get_azimuth)\n",
    "main['Elevation'] = main.DateTime.apply(get_elevation)\n",
    "indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)\n",
    "main['mean_ele'] = main.Elevation.rolling(window=indexer, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "875be874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding some additional features (square of these two features)\n",
    "main['sq_cloud'] = main.two_hour_cloud ** 2\n",
    "main['sq_hum'] = main.two_hour_hum ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4653fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = main[['DateTime','Generation','Elevation','Azimuth','two_hour_hum','two_hour_cloud','mean_ele',\n",
    "             'prop_hum','prop_cloud',\n",
    "             'prop_hum2','prop_cloud2',\n",
    "             'prop_cloud3','prop_hum3',\n",
    "             'prop_cloud4','prop_hum4',\n",
    "             'WWCode','WindDirection',\n",
    "             'sq_cloud','sq_hum','WindSpeed'\n",
    "             \n",
    "            ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e77ccad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding of humidity feature\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X= main[['two_hour_hum']]\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=5, random_state=0).fit(X)\n",
    "b = kmeans.labels_\n",
    "\n",
    "a = kmeans.predict(X)\n",
    "\n",
    "c = kmeans.cluster_centers_\n",
    "main['cluster_c'] = b\n",
    "\n",
    "main['hh1'] = np.where((main.cluster_c == 0), 1, 0)\n",
    "main['hh2'] = np.where((main.cluster_c == 1), 1, 0)\n",
    "main['hh3'] = np.where((main.cluster_c == 2), 1, 0)\n",
    "main['hh4'] = np.where((main.cluster_c == 3), 1, 0)\n",
    "main['hh5'] = np.where((main.cluster_c == 4), 1, 0)\n",
    "main['hh6'] = np.where((main.cluster_c == 5), 1, 0)\n",
    "#main['ws7'] = np.where((main.cluster_c == 6), 1, 0)\n",
    "#main['ws8'] = np.where((main.cluster_c == 7), 1, 0)\n",
    "#main['ws9'] = np.where((main.cluster_c == 8), 1, 0)\n",
    "#main['ws10'] = np.where((main.cluster_c == 9), 1, 0)\n",
    "\n",
    "main.drop(['cluster_c','two_hour_hum'],axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e7c0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding of WindSpeed feature\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X= main[['WindSpeed']]\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(X)\n",
    "b = kmeans.labels_\n",
    "\n",
    "a = kmeans.predict(X)\n",
    "\n",
    "c = kmeans.cluster_centers_\n",
    "main['cluster_c'] = b\n",
    "\n",
    "main['ws1'] = np.where((main.cluster_c == 0), 1, 0)\n",
    "main['ws2'] = np.where((main.cluster_c == 1), 1, 0)\n",
    "main['ws3'] = np.where((main.cluster_c == 2), 1, 0)\n",
    "main['ws4'] = np.where((main.cluster_c == 3), 1, 0)\n",
    "main['ws5'] = np.where((main.cluster_c == 4), 1, 0)\n",
    "main['ws6'] = np.where((main.cluster_c == 5), 1, 0)\n",
    "main['ws7'] = np.where((main.cluster_c == 6), 1, 0)\n",
    "#main['ws8'] = np.where((main.cluster_c == 7), 1, 0)\n",
    "#main['ws9'] = np.where((main.cluster_c == 8), 1, 0)\n",
    "#main['ws10'] = np.where((main.cluster_c == 9), 1, 0)\n",
    "\n",
    "main.drop(['cluster_c','WindSpeed'],axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50967f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One hot encoding of WindDirection feature\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X= main[['WindDirection']]\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(X)\n",
    "b = kmeans.labels_\n",
    "\n",
    "a = kmeans.predict(X)\n",
    "\n",
    "c = kmeans.cluster_centers_\n",
    "main['cluster_c'] = b\n",
    "\n",
    "main['wd1'] = np.where((main.cluster_c == 0), 1, 0)\n",
    "main['wd2'] = np.where((main.cluster_c == 1), 1, 0)\n",
    "main['wd3'] = np.where((main.cluster_c == 2), 1, 0)\n",
    "main['wd4'] = np.where((main.cluster_c == 3), 1, 0)\n",
    "main['wd5'] = np.where((main.cluster_c == 4), 1, 0)\n",
    "main['wd6'] = np.where((main.cluster_c == 5), 1, 0)\n",
    "main['wd7'] = np.where((main.cluster_c == 6), 1, 0)\n",
    "main['wd8'] = np.where((main.cluster_c == 7), 1, 0)\n",
    "main['wd9'] = np.where((main.cluster_c == 8), 1, 0)\n",
    "main['wd10'] = np.where((main.cluster_c == 9), 1, 0)\n",
    "\n",
    "main.drop(['cluster_c','WindDirection'],axis = 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a48064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = main[main['WWCode'].isna()].index\n",
    "main.drop(index_names, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f53ad",
   "metadata": {},
   "source": [
    "# K-means Clustering for some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42409764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X= main[['WWCode']]\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=4, random_state=0).fit(X)\n",
    "b = kmeans.labels_\n",
    "\n",
    "a = kmeans.predict(X)\n",
    "\n",
    "c = kmeans.cluster_centers_\n",
    "main['cluster'] = b\n",
    "\n",
    "main['w1'] = np.where((main.cluster == 1), 1, 0)\n",
    "main['w2'] = np.where((main.cluster == 2), 1, 0)\n",
    "main['w3'] = np.where((main.cluster == 3), 1, 0)\n",
    "main['w4'] = np.where((main.cluster == 0), 1, 0)\n",
    "#main['w5'] = np.where((main.cluster == 4), 1, 0)\n",
    "#main['w6'] = np.where((main.cluster == 5), 1, 0)\n",
    "#main['w7'] = np.where((main.cluster == 6), 1, 0)\n",
    "\n",
    "main.drop(['cluster','WWCode'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd1554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe75f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.loc[main.mean_ele < 0, 'Azimuth'] = 0\n",
    "main.loc[main.mean_ele < 0, 'mean_ele'] = 0\n",
    "\n",
    "main['new_azi'] = 180 - main.Azimuth\n",
    "main.drop('Azimuth',axis= 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c44e4897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X= main[['mean_ele']]\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(X)\n",
    "b = kmeans.labels_\n",
    "\n",
    "a = kmeans.predict(X)\n",
    "\n",
    "c = kmeans.cluster_centers_\n",
    "main['cluster'] = b\n",
    "\n",
    "\n",
    "main['cluster1'] = np.where((main.cluster == 1), 1, 0)\n",
    "main['cluster2'] = np.where((main.cluster == 2), 1, 0)\n",
    "main['cluster3'] = np.where((main.cluster == 3), 1, 0)\n",
    "main['cluster4'] = np.where((main.cluster == 4), 1, 0)\n",
    "main['cluster5'] = np.where((main.cluster == 5), 1, 0)\n",
    "main['cluster6'] = np.where((main.cluster == 6), 1, 0)\n",
    "main['cluster7'] = np.where((main.cluster == 7), 1, 0)\n",
    "main['cluster8'] = np.where((main.cluster == 8), 1, 0)\n",
    "main['cluster9'] = np.where((main.cluster == 9), 1, 0)\n",
    "main['cluster10'] = np.where((main.cluster == 0), 1, 0)\n",
    "\n",
    "\n",
    "main.drop(['cluster'],axis = 1,inplace = True)\n",
    "main.drop(['Elevation'],axis = 1,inplace = True)\n",
    "main.drop(['mean_ele'],axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf7d4a",
   "metadata": {},
   "source": [
    "# Handling missing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbd2e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.at[26303,'prop_hum2'] = test_set.at[26300,'prop_hum2']\n",
    "test_set.at[26302,'prop_hum2'] = test_set.at[26300,'prop_hum2']\n",
    "test_set.at[26301,'prop_hum2'] = test_set.at[26300,'prop_hum2']\n",
    "\n",
    "test_set.at[26303,'prop_cloud2'] = test_set.at[26300,'prop_cloud2']\n",
    "test_set.at[26302,'prop_cloud2'] = test_set.at[26300,'prop_cloud2']\n",
    "test_set.at[26301,'prop_cloud2'] = test_set.at[26300,'prop_cloud2']\n",
    "\n",
    "test_set.at[26303,'prop_cloud3'] = test_set.at[26301,'prop_cloud3']\n",
    "test_set.at[26302,'prop_cloud3'] = test_set.at[26301,'prop_cloud3']\n",
    "\n",
    "test_set.at[26303,'prop_hum3'] = test_set.at[26301,'prop_hum3']\n",
    "test_set.at[26302,'prop_hum3'] = test_set.at[26301,'prop_hum3']\n",
    "\n",
    "test_set.at[26303,'prop_cloud4'] = test_set.at[26302,'prop_cloud4']\n",
    "\n",
    "test_set.at[26303,'prop_hum4'] = test_set.at[26302,'prop_hum4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b851c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = main[main.Generation.isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1979577",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = main.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc69712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = main[main.DateTime.dt.year != 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b08258d",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "98743c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = main[((main.DateTime.dt.month != 11) & (main.DateTime.dt.year == 2021)) | (main.DateTime.dt.year == 2020)]\n",
    "test = main[(main.DateTime.dt.month == 11) & (main.DateTime.dt.year == 2021)]\n",
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bad26802",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = main.drop(['Generation','DateTime'],axis = 1)\n",
    "y_train = main['Generation']\n",
    "X_test = test_set.drop(['Generation','DateTime'],axis = 1)\n",
    "y_test = test_set['Generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a25bda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.25863254035309"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = RandomForestRegressor(max_depth= 100, max_features= 'auto', min_samples_leaf= 20, \n",
    "                              min_samples_split= 2,n_estimators= 50).fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(predictions,y_test)\n",
    "rmse = mse**0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "27c5bacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.842843232867692"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgbm\n",
    "model = lgbm.sklearn.LGBMRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(predictions,y_test)\n",
    "rmse = mse**0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8adff9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "model = CatBoostRegressor().fit(X_train,y_train,verbose = False)\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "078c349a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.22125224028979"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(predictions,y_test)\n",
    "rmse = mse**0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3eef81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "estimator = RandomForestRegressor(max_depth= 100, max_features= 'auto', min_samples_leaf= 20, \n",
    "                              min_samples_split= 2,n_estimators= 50)\n",
    "selector = RFE(estimator, n_features_to_select=45, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716635b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abd8d32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.028\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(train.prop_cloud,train.Generation)\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97930b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['pred'] = predictions\n",
    "X_test['real'] = test.Generation\n",
    "X_test['date'] = test.DateTime\n",
    "X_test['diff'] = X_test.real- X_test.pred\n",
    "X_test['hour'] = X_test.date.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb826b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3d2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fb201e0",
   "metadata": {},
   "source": [
    "# Submission steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e14bd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['sada'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bc7ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.drop(['Generation'],axis= 1,inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4e50039",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.rename(columns = {'sada':'Generation'},inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3f67464",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = sample_submission.set_index('DateTime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86d682e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('enerjisa_sub15.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8c8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
